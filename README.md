# azure-ai-mvp

âœ… ëª©í‘œ ìš”ì•½

ì…ë ¥: ë§¤ì¼ ìƒì„±ë˜ëŠ” ì„œë²„ ë¡œê·¸ íŒŒì¼ (.log, .txt, .json ë“±)

ì²˜ë¦¬: Azure Functionì´ ë¡œê·¸ ì—…ë¡œë“œ ê°ì§€ â†’ íŠ¹ì • ì •ê·œì‹ íƒì§€ â†’ RAG ë²¡í„°í™”

ê²€ìƒ‰: RAG ê¸°ë°˜ ì±—ë´‡ì´ Streamlitì—ì„œ ë¡œê·¸ ê¸°ë°˜ ì§ˆì˜ ì‘ë‹µ ì œê³µ

ë³´ì•ˆ: ë‚´ë¶€ ë°ì´í„°ë¡œë§Œ í•™ìŠµ, ì™¸ë¶€ ìœ ì¶œ ì—†ìŒ

ğŸ“… 3ì¼ ê°œë°œ ê³„íš (Day-by-Day)
ğŸ“Œ Day 1 â€“ í”„ë¡œì íŠ¸ êµ¬ì¡° + Azure ë¦¬ì†ŒìŠ¤ + ê¸°ë³¸ íŒŒì´í”„ë¼ì¸

ëª©í‘œ: ì „ì²´ íë¦„ êµ¬ì„±ê³¼ Azure ë¦¬ì†ŒìŠ¤ ì¤€ë¹„

1.1. í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ê³„
logbot_project/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ azure_function/       # ë¡œê·¸ ì—…ë¡œë“œ íŠ¸ë¦¬ê±° ë° ì •ê·œì‹ ì²˜ë¦¬
â”‚   â”œâ”€â”€ rag_pipeline/         # ì„ë² ë”© + ë²¡í„°DB ì €ì¥
â”‚   â””â”€â”€ langchain/            # QA ì²´ì¸ êµ¬ì„±
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ streamlit_app/        # ì§ˆì˜ ì‘ë‹µ UI
â”œâ”€â”€ data/
â”‚   â””â”€â”€ logs/                 # ë¡œê·¸ ë³´ê´€
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ regex_patterns.json   # íƒì§€ ì •ê·œì‹
â””â”€â”€ .env

1.2. Azure ë¦¬ì†ŒìŠ¤ ìƒì„± (Azure Portal or CLI)

âœ… Azure Storage Blob (log ì—…ë¡œë“œìš©)

âœ… Azure Function App (Blob Trigger ë°©ì‹)

âœ… Azure AI Search (ë²¡í„° ê²€ìƒ‰ìš©)

âœ… Azure AI Services (ì„ë² ë”© / ì–¸ì–´ë¶„ì„)

âœ… Azure Language or OpenAI (GPT-4.1-mini API Key)

1.3. Azure Function ì¤€ë¹„

íŠ¸ë¦¬ê±°: Blob container log-upload/ì— íŒŒì¼ì´ ì—…ë¡œë“œë˜ë©´ ì‹¤í–‰

ê¸°ëŠ¥: ë¡œê·¸ì—ì„œ ì§€ì •í•œ ì •ê·œì‹(ì˜ˆ: ERROR, Exception) íƒì§€

ê²°ê³¼: íƒì§€ ë‚´ìš©ê³¼ í•¨ê»˜ ë²¡í„°í™” ìš”ì²­ (â†’ rag_pipeline)

â˜‘ï¸ Output ì˜ˆì‹œ JSON:

{
  "filename": "server_20250927.log",
  "matches": ["NullPointerException at line 293", "Connection timeout"],
  "summary": "2 errors detected",
  "upload_time": "2025-09-27T00:03:21"
}

ğŸ“Œ Day 2 â€“ RAG êµ¬ì„± (LangChain ê¸°ë°˜) + ë²¡í„° ì €ì¥
2.1. RAG êµ¬ì„± ìš”ì†Œ

Document Loader: ë¡œê·¸ íŒŒì¼ì˜ ë¼ì¸ë³„ entry ë‚˜ëˆ„ê¸°

Text Splitter: LangChainì˜ CharacterTextSplitter ì‚¬ìš©

Embedding Model: AzureOpenAIEmbeddings or OpenAIEmbeddings

Vector Store: Azure Cognitive Search

Retriever: SearchRetriever() + filter ì¡°ê±´ (íŒŒì¼ëª…, ë‚ ì§œ ë“±)

2.2. LangChain QA Chain êµ¬ì„±

ConversationalRetrievalChain ì‚¬ìš©

ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: "ì„œë²„ ë¡œê·¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ë¬¸ì œ ì„¤ëª…ê³¼ ì›ì¸ì„ ìš”ì•½í•´ì£¼ì„¸ìš”."

Memory: LangGraphë¡œ ê°„ë‹¨í•œ ì„¸ì…˜ íë¦„ êµ¬ì„± ê°€ëŠ¥ (ì˜µì…˜)

2.3. LangSmith / LangFuse ì—°ë™

LangSmith: QA ì²´ì¸ ì¶”ì  ë° debug

LangFuse: ì‘ë‹µ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ë° ì—ëŸ¬ ì¶”ì 

ğŸ“Œ Day 3 â€“ Streamlit ì±—ë´‡ UI + í†µí•© í…ŒìŠ¤íŠ¸ + ë§ˆë¬´ë¦¬
3.1. Streamlit ì±—ë´‡ UI

ì…ë ¥ì°½: ì‚¬ìš©ì ì§ˆë¬¸

ì˜µì…˜:

ë‚ ì§œ ì„ íƒ (â†’ í•´ë‹¹ ë¡œê·¸íŒŒì¼ë§Œ ê²€ìƒ‰)

ì—ëŸ¬ íƒ€ì… í•„í„° (ì˜ˆ: Timeout, NullPointer, ì‚¬ìš©ì ì •ì˜)

ì¶œë ¥: ì‘ë‹µ + ê´€ë ¨ ë¡œê·¸ í•˜ì´ë¼ì´íŠ¸

st.title("ğŸªµ ë¡œê·¸ ë¶„ì„ ì±—ë´‡")
query = st.text_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”?")
if query:
    answer = qa_chain.run({"question": query})
    st.write(answer)

3.2. í†µí•© íë¦„ í…ŒìŠ¤íŠ¸

ë¡œê·¸ íŒŒì¼ ì—…ë¡œë“œ â†’ Function íŠ¸ë¦¬ê±° â†’ ì •ê·œì‹ íƒì§€ ë° ì„ë² ë”©

ê²€ìƒ‰ ê°€ëŠ¥í•œ ë²¡í„° ì €ì¥ í™•ì¸

Streamlitì—ì„œ ì§ˆì˜ â†’ ë¡œê·¸ ê¸°ë°˜ ì‘ë‹µ í™•ì¸

3.3. ë¬¸ì„œí™” ë° README ì •ë¦¬

ì‹¤í–‰ ë°©ë²•, í™˜ê²½ë³€ìˆ˜ ì„¤ì •, ë¦¬ì†ŒìŠ¤ ì˜ì¡´ì„± ëª…ì‹œ

âš™ï¸ ê¸°ìˆ  ìŠ¤íƒ ìš”ì•½
ëª©ì 	ê¸°ìˆ 
ì—…ë¡œë“œ ê°ì§€	Azure Function (Blob Trigger)
ë¬¸ì„œ ì „ì²˜ë¦¬	LangChain Loader + Splitter
ë²¡í„° ì„ë² ë”©	Azure OpenAI Embedding
ê²€ìƒ‰ ë°±ì—”ë“œ	Azure AI Search
QA ì²´ì¸	LangChain ConversationalRetrievalChain
í”„ë¡ íŠ¸ì—”ë“œ	Streamlit
ë¶„ì„ ì¶”ì 	LangSmith, LangFuse
ğŸ” ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

ë¡œê·¸íŒŒì¼ì€ ì ˆëŒ€ ì™¸ë¶€ ì „ì†¡ ê¸ˆì§€

Azure Function + Storage + SearchëŠ” ê°™ì€ ë¦¬ì†ŒìŠ¤ ê·¸ë£¹ ë‚´ë¶€

.env ì‚¬ìš©í•˜ì—¬ í‚¤, ì •ê·œì‹ ê²½ë¡œ ë“± ë³´ê´€

ğŸ”„ ì„ íƒì ìœ¼ë¡œ ê³ ë ¤í•  í™•ì¥

LangGraphë¡œ ìƒíƒœ íë¦„ êµ¬ì„± (ì˜ˆ: íŒŒì¼ ì—…ë¡œë“œ â†’ ì²˜ë¦¬ ì¤‘ â†’ ì™„ë£Œ)

LLM ì‘ë‹µì„ ê¸°ë°˜ìœ¼ë¡œ ì¶”ë¡ ëœ ë¬¸ì œ ìš”ì•½ ìë™ ìƒì„±

PDFë¡œ ë¦¬í¬íŠ¸ ì €ì¥ or ì´ë©”ì¼ ì „ì†¡

ì´ì œ ì´ ê³„íšì— ëŒ€í•œ ì˜ê²¬ì´ë‚˜ ìˆ˜ì •í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì„ ë§ì”€í•´ ì£¼ì„¸ìš”!
(ì˜ˆ: ë¡œê·¸íŒŒì¼ í¬ë§·, ì •ê·œì‹ êµ¬ì²´í™”, LangGraph ë¹„ì¤‘ í™•ëŒ€, ì±—ë´‡ UI ì¶”ê°€ê¸°ëŠ¥ ë“±)




1ì¼ì°¨ ============================================================================

ì¢‹ìŠµë‹ˆë‹¤. ì´ì œë¶€í„° ì €ëŠ” Azure ê¸°ë°˜ RAG + LangChain + ë¡œê·¸ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì „ë¬¸ê°€ì˜ ì…ì¥ì—ì„œ,
1ì¼ì°¨ ì‘ì—…ì„ ìˆœì„œë³„ë¡œ ì„¸ë¶„í™”í•´ì„œ **"ë³µë¶™í•´ì„œ ë°”ë¡œ ì“¸ ìˆ˜ ìˆëŠ” ìˆ˜ì¤€"**ìœ¼ë¡œ ë“œë¦´ê²Œìš”.
ë‹¹ì‹ ì´ 3ì¼ ì•ˆì— ì™„ì„±í•  ìˆ˜ ìˆë„ë¡ ì´ˆë³´ì ë‚œì´ë„, í˜„ì—… ì‹¤ìš©ì„±, ë¹ ë¥¸ ë°˜ë³µ ê²€ì¦ì„ ê³ ë ¤í–ˆìŠµë‹ˆë‹¤.

ğŸ“… 1ì¼ì°¨ ìƒì„¸ ì‘ì—… ìˆœì„œ

ëª©í‘œ: Azure ë¦¬ì†ŒìŠ¤ ìƒì„± + ë¡œê·¸ íŠ¸ë¦¬ê±° íŒŒì´í”„ë¼ì¸ ê¸°ë³¸ êµ¬ì„± + í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ì •ë¦¬

âœ… 1.1. í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„± (ë¡œì»¬ ê°œë°œ í™˜ê²½ ê¸°ì¤€)
mkdir logbot_project && cd logbot_project

# ê¸°ë³¸ êµ¬ì¡° ìƒì„±
mkdir -p backend/azure_function
mkdir -p backend/rag_pipeline
mkdir -p backend/langchain
mkdir -p frontend/streamlit_app
mkdir -p data/logs
mkdir -p configs

touch .env


ì°¸ê³ : .envëŠ” API í‚¤, connection string, ì •ê·œì‹ ê²½ë¡œ ë“±ì„ ì €ì¥í•  ìš©ë„

âœ… 1.2. Azure ë¦¬ì†ŒìŠ¤ ê·¸ë£¹ ë° ë¦¬ì†ŒìŠ¤ ìƒì„±

ğŸ’¡ CLI ë˜ëŠ” Azure Portal ì¤‘ ì„ íƒ ê°€ëŠ¥í•˜ì§€ë§Œ, Azure CLIë¡œ ëª…ë ¹ì–´ ë“œë¦´ê²Œìš”.

# í™˜ê²½ ë³€ìˆ˜ ì •ì˜ (ë³µì‚¬ í›„ ê°’ë§Œ ìˆ˜ì •)
RESOURCE_GROUP=logbot-rg
LOCATION=eastus
STORAGE_ACCOUNT=logbotstorage$RANDOM
FUNCTION_APP=logbot-function$RANDOM
SEARCH_SERVICE=logbot-search
COGNITIVE_SERVICE=logbot-ai

# 1. ë¦¬ì†ŒìŠ¤ ê·¸ë£¹ ìƒì„±
az group create --name $RESOURCE_GROUP --location $LOCATION

# 2. Storage ê³„ì • ìƒì„±
az storage account create \
  --name $STORAGE_ACCOUNT \
  --location $LOCATION \
  --resource-group $RESOURCE_GROUP \
  --sku Standard_LRS

# 3. Function Appì„ ìœ„í•œ App Service Plan ìƒì„±
az functionapp plan create \
  --resource-group $RESOURCE_GROUP \
  --name logbot-plan \
  --location $LOCATION \
  --number-of-workers 1 \
  --sku B1 \
  --is-linux

# 4. Function App ìƒì„± (Python ëŸ°íƒ€ì„)
az functionapp create \
  --resource-group $RESOURCE_GROUP \
  --plan logbot-plan \
  --name $FUNCTION_APP \
  --storage-account $STORAGE_ACCOUNT \
  --runtime python \
  --runtime-version 3.10 \
  --functions-version 4

# 5. Azure AI Search ìƒì„±
az search service create \
  --name $SEARCH_SERVICE \
  --resource-group $RESOURCE_GROUP \
  --location $LOCATION \
  --sku basic

# 6. Azure AI ì„œë¹„ìŠ¤ ìƒì„± (ì„ë² ë”©ìš©)
az cognitiveservices account create \
  --name $COGNITIVE_SERVICE \
  --resource-group $RESOURCE_GROUP \
  --kind CognitiveServices \
  --sku S0 \
  --location $LOCATION \
  --yes


ìƒì„± ì™„ë£Œ í›„ í•„ìš”í•œ í‚¤ë“¤ì„ .envì— ì €ì¥í•´ ë‘ì„¸ìš”
(Function Key, Cognitive Services Key, Search Admin Key ë“±)

âœ… 1.3. Azure Blob Storage ì»¨í…Œì´ë„ˆ ìƒì„± ë° ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸
# Storage Connection String í™•ì¸
az storage account show-connection-string \
  --name $STORAGE_ACCOUNT \
  --resource-group $RESOURCE_GROUP \
  --query connectionString \
  --output tsv

# ë¡œì»¬ì—ì„œ test ì»¨í…Œì´ë„ˆ ë§Œë“¤ê³  ë¡œê·¸íŒŒì¼ ì—…ë¡œë“œ
az storage container create \
  --name log-upload \
  --account-name $STORAGE_ACCOUNT \
  --public-access off

az storage blob upload \
  --container-name log-upload \
  --file ./data/logs/sample_log.txt \
  --name 2025-09-27.log \
  --account-name $STORAGE_ACCOUNT

âœ… 1.4. Azure Function ë¡œì»¬ ê°œë°œ ë° ë°°í¬ ì¤€ë¹„
cd backend/azure_function
func init log_uploader --python
cd log_uploader
func new --name LogTrigger --template "Azure Blob Storage trigger" --authlevel "function"


ğŸ”§ ìƒì„±ëœ LogTrigger/__init__.pyë¥¼ ì•„ë˜ì™€ ê°™ì´ í¸ì§‘í•˜ì„¸ìš”:

import logging
import re
import os
import json

import azure.functions as func

PATTERN_LIST = [
    r"Exception",
    r"Timeout",
    r"Connection refused",
    r"NullPointerException",
]

def main(myblob: func.InputStream):
    logging.info(f"Processing blob: {myblob.name}, Size: {myblob.length} bytes")

    content = myblob.read().decode("utf-8")
    matches = []
    for pattern in PATTERN_LIST:
        matches += re.findall(pattern, content)

    summary = {
        "filename": myblob.name,
        "match_count": len(matches),
        "matched_patterns": matches,
    }

    logging.info(f"Match Summary: {json.dumps(summary, indent=2)}")


ğŸ”§ function.json ì„¤ì • í™•ì¸ (path, connection ë“±):

{
  "scriptFile": "__init__.py",
  "bindings": [
    {
      "name": "myblob",
      "type": "blobTrigger",
      "direction": "in",
      "path": "log-upload/{name}",
      "connection": "AzureWebJobsStorage"
    }
  ]
}

âœ… 1.5. Function ë¡œì»¬ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
# ê°€ìƒí™˜ê²½ ë° ì˜ì¡´ ì„¤ì¹˜
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt

# ë¡œì»¬ ì‹¤í–‰
func start

âœ… 1.6. ê¸°ëŠ¥ í™•ì¸ ì²´í¬ë¦¬ìŠ¤íŠ¸

 ë¡œê·¸íŒŒì¼ ì—…ë¡œë“œ ì‹œ Function íŠ¸ë¦¬ê±° ì‘ë™ í™•ì¸

 ì •ê·œì‹ íŒ¨í„´ íƒì§€ ë¡œê·¸ ì¶œë ¥ í™•ì¸

 sample_log.txt ì•ˆì— ì¼ë¶€ëŸ¬ "NullPointerException" ê°™ì€ ë¬¸ìì—´ í¬í•¨í•´ í…ŒìŠ¤íŠ¸

 ì •ê·œì‹ì€ configs/regex_patterns.json ìœ¼ë¡œ ì¶”í›„ ë¶„ë¦¬ ê°€ëŠ¥

âœ… 1.7. TODOë¡œ ë‚¨ê¸¸ ê²ƒ (Day 2ë¡œ ë„˜ê¹€)

 íƒì§€ëœ ë¡œê·¸ â†’ Azure Searchì— ì €ì¥í•  ìˆ˜ ìˆë„ë¡ í›„ì†ì²˜ë¦¬

 LangChainì—ì„œ ë²¡í„°ê²€ìƒ‰ ê°€ëŠ¥í•˜ë„ë¡ êµ¬ì„±

 LangSmith / LangFuse ì—°ë™

 Streamlit ì±—ë´‡ ì—°ê²°

âœ… 1ì¼ì°¨ ê²°ê³¼ë¬¼

Azure ë¦¬ì†ŒìŠ¤ êµ¬ì„± ì™„ë£Œ

ë¡œê·¸ ì—…ë¡œë“œ â†’ ì •ê·œì‹ íƒì§€ â†’ Function ë¡œê·¸ ì¶œë ¥ê¹Œì§€ í™•ì¸

í”„ë¡œì íŠ¸ í´ë” ë° ê°œë°œí™˜ê²½ ì„¸íŒ… ì™„ë£Œ

ğŸ“Œ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ

1ì¼ì°¨ ì§„í–‰ í›„, ë¡œê·¸ íŒŒì¼ í¬ë§·ì„ ê³µìœ í•´ ì£¼ì‹œë©´
ğŸ‘‰ LangChain TextLoader + Splitter + Document ì¤€ë¹„ê¹Œì§€ ì´ì–´ì„œ ì„¤ê³„í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.





2ì¼ì°¨ ======================================================================================

ì¢‹ì•„ìš” ğŸ‘
ì´ì œ 2ì¼ì°¨ëŠ” RAG íŒŒì´í”„ë¼ì¸ + Azure AI Search ì—°ê²°ì´ í•µì‹¬ì…ë‹ˆë‹¤.
ëª©í‘œëŠ” ì •ê·œì‹ìœ¼ë¡œ íƒì§€í•œ ë¡œê·¸ ë‚´ìš©ì„ Azure Cognitive Search(ë²¡í„° DB)ì— ë„£ê³ , LangChainìœ¼ë¡œ ê²€ìƒ‰ + ì§ˆë¬¸ì‘ë‹µì´ ê°€ëŠ¥í•˜ê²Œ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤.

ì•„ë˜ ë‹¨ê³„ëŠ” ì‹¤ë¬´í˜•ì´ë©´ì„œë„ 3ì¼ ì•ˆì— ì™„ì„± ê°€ëŠ¥í•œ ë‚œì´ë„ë¡œ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤.

ğŸ“… 2ì¼ì°¨ ìƒì„¸ ê³„íš

ëª©í‘œ: RAG íŒŒì´í”„ë¼ì¸ êµ¬ì„± + Azure Search ì¸ë±ìŠ¤ ìƒì„± + LangChainìœ¼ë¡œ ì§ˆì˜ì‘ë‹µ ê°€ëŠ¥ ìƒíƒœ ë§Œë“¤ê¸°

âœ… 2.1. Python í™˜ê²½ ì¤€ë¹„ (ë²¡í„°í™”/ì¸ë±ì‹± ìŠ¤í¬ë¦½íŠ¸ìš©)
cd backend/rag_pipeline
python -m venv .venv
source .venv/bin/activate    # (Windows: .venv\Scripts\activate)

pip install langchain-openai azure-search-documents azure-identity python-dotenv


âš¡ ì¶”ê°€ íŒ¨í‚¤ì§€:

langchain-openai : OpenAI ì„ë² ë”© & Chat ëª¨ë¸

azure-search-documents : Azure Cognitive Search SDK

azure-identity : Azure ìê²© ì¦ëª…

python-dotenv : .env ë¡œë¶€í„° í‚¤ ë¡œë”©

âœ… 2.2. .env íŒŒì¼ ê°±ì‹ 
# .env
AZURE_SEARCH_ENDPOINT=https://<SEARCH_SERVICE>.search.windows.net
AZURE_SEARCH_KEY=<ê´€ë¦¬ìí‚¤>
AZURE_OPENAI_API_KEY=<OpenAI Key>
AZURE_OPENAI_EMBEDDING_MODEL=text-embedding-3-small
SEARCH_INDEX_NAME=log-index


ğŸ’¡ AZURE_SEARCH_KEY ëŠ” Azure Portal â†’ AI Search â†’ Keys & Endpoint â†’ Admin Key ë³µì‚¬
ğŸ’¡ OpenAI ëŒ€ì‹  Azure OpenAIë¥¼ ì“°ë ¤ë©´ AZURE_OPENAI_ENDPOINT ì™€ AZURE_OPENAI_API_VERSIONë„ ì¶”ê°€

âœ… 2.3. Azure Cognitive Search ì¸ë±ìŠ¤ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

create_search_index.py ì‘ì„±:

import os
from azure.core.credentials import AzureKeyCredential
from azure.search.documents.indexes import SearchIndexClient
from azure.search.documents.indexes.models import (
    SearchIndex, SimpleField, SearchFieldDataType, SearchableField, VectorSearch,
    VectorSearchAlgorithmConfiguration, HnswAlgorithmConfiguration, VectorSearchProfile,
    SearchField
)
from dotenv import load_dotenv

load_dotenv()

endpoint = os.environ["AZURE_SEARCH_ENDPOINT"]
key = os.environ["AZURE_SEARCH_KEY"]
index_name = os.environ["SEARCH_INDEX_NAME"]

index_client = SearchIndexClient(endpoint, AzureKeyCredential(key))

fields = [
    SimpleField(name="id", type=SearchFieldDataType.String, key=True),
    SearchableField(name="content", type=SearchFieldDataType.String),
    SimpleField(name="filename", type=SearchFieldDataType.String, filterable=True),
    SimpleField(name="timestamp", type=SearchFieldDataType.String, filterable=True),
    SearchField(
        name="content_vector",
        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),
        searchable=True,
        vector_search_dimensions=1536,
        vector_search_profile="default"
    )
]

vector_search = VectorSearch(
    algorithm_configurations=[
        HnswAlgorithmConfiguration(name="default", kind="hnsw")
    ],
    profiles=[VectorSearchProfile(name="default", algorithm_configuration_name="default")]
)

index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)

# ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ í›„ ì¬ìƒì„±(ê°œë°œìš©)
try:
    index_client.delete_index(index_name)
    print(f"Deleted existing index {index_name}")
except:
    pass

index_client.create_index(index)
print(f"Index {index_name} created!")


âš¡ ì‹¤í–‰:

python create_search_index.py

âœ… 2.4. ë²¡í„°í™” & ë¬¸ì„œ ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸

upload_docs.py ì‘ì„±:

import os, uuid, datetime
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from langchain_openai import OpenAIEmbeddings
from dotenv import load_dotenv

load_dotenv()

endpoint = os.environ["AZURE_SEARCH_ENDPOINT"]
key = os.environ["AZURE_SEARCH_KEY"]
index_name = os.environ["SEARCH_INDEX_NAME"]

search_client = SearchClient(endpoint=endpoint, index_name=index_name, credential=AzureKeyCredential(key))
embeddings = OpenAIEmbeddings(model=os.getenv("AZURE_OPENAI_EMBEDDING_MODEL"), api_key=os.getenv("AZURE_OPENAI_API_KEY"))

def upload_log(filename, content):
    # ì„ë² ë”© ìƒì„±
    vector = embeddings.embed_documents([content])[0]

    doc = {
        "id": str(uuid.uuid4()),
        "content": content,
        "filename": filename,
        "timestamp": datetime.datetime.utcnow().isoformat(),
        "content_vector": vector
    }

    search_client.upload_documents([doc])
    print(f"Uploaded: {filename}")

if __name__ == "__main__":
    # ìƒ˜í”Œ í…ŒìŠ¤íŠ¸
    with open("../azure_function/log_uploader/sample_log.txt", "r", encoding="utf-8") as f:
        text = f.read()
    upload_log("sample_log.txt", text)


âš¡ ì‹¤í–‰:

python upload_docs.py


â†’ Cognitive Search í¬í„¸ì—ì„œ ì¸ë±ìŠ¤ ì•ˆì— ë¬¸ì„œê°€ ì˜¬ë¼ê°”ëŠ”ì§€ í™•ì¸.

âœ… 2.5. Azure Functionê³¼ ì—°ë™ (ìë™ ì—…ë¡œë“œ)

Day1ì—ì„œ ë§Œë“  function_app.py ì•ˆì—, ì •ê·œì‹ íƒì§€ í›„ ë²¡í„° ì—…ë¡œë“œ í˜¸ì¶œ ì¶”ê°€:

import logging
import azure.functions as func
import re, json, os, uuid, datetime
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from openai import OpenAI

app = func.FunctionApp()

# Azure Search í´ë¼ì´ì–¸íŠ¸
search_client = SearchClient(
    endpoint=os.environ["AZURE_SEARCH_ENDPOINT"],
    index_name=os.environ["SEARCH_INDEX_NAME"],
    credential=AzureKeyCredential(os.environ["AZURE_SEARCH_KEY"])
)

# OpenAI ì„ë² ë”©
from langchain_openai import OpenAIEmbeddings
embeddings = OpenAIEmbeddings(model=os.getenv("AZURE_OPENAI_EMBEDDING_MODEL"), api_key=os.getenv("AZURE_OPENAI_API_KEY"))

@app.function_name(name="LogTrigger")
@app.blob_trigger(arg_name="myblob", path="log-upload/{name}", connection="AzureWebJobsStorage")
def log_trigger(myblob: func.InputStream):
    logging.info(f"Processing blob: {myblob.name}")
    content = myblob.read().decode("utf-8")

    # ì •ê·œì‹ íƒì§€
    patterns = [r"Exception", r"Timeout", r"Connection refused"]
    matches = []
    for p in patterns:
        matches.extend(re.findall(p, content))
    logging.info(f"Match Summary: {matches}")

    # ë²¡í„° ìƒì„± í›„ ì—…ë¡œë“œ
    vector = embeddings.embed_documents([content])[0]
    doc = {
        "id": str(uuid.uuid4()),
        "content": content,
        "filename": myblob.name,
        "timestamp": datetime.datetime.utcnow().isoformat(),
        "content_vector": vector
    }
    search_client.upload_documents([doc])
    logging.info("Uploaded to Azure Search")


âš¡ ë¡œì»¬ì—ì„œ ë‹¤ì‹œ func start í›„ Blob ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸ â†’ Cognitive Search ì¸ë±ìŠ¤ì— ìë™ ë“±ë¡ë˜ëŠ”ì§€ í™•ì¸

âœ… 2.6. LangChain Retriever + QA Chain í…ŒìŠ¤íŠ¸

test_qa.py ì‘ì„±:

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain_community.vectorstores.azuresearch import AzureSearch

load_dotenv()

vectorstore = AzureSearch(
    azure_search_endpoint=os.getenv("AZURE_SEARCH_ENDPOINT"),
    azure_search_key=os.getenv("AZURE_SEARCH_KEY"),
    index_name=os.getenv("SEARCH_INDEX_NAME"),
    embedding_function=None,  # ì´ë¯¸ ì¸ë±ìŠ¤ì— ë²¡í„° ìˆìŒ
)

retriever = vectorstore.as_retriever(search_type="similarity", k=3)
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

qa = RetrievalQA.from_chain_type(llm, retriever=retriever)

query = "ìµœê·¼ ì—…ë¡œë“œëœ ë¡œê·¸ì—ì„œ Exceptionì´ ë°œìƒí•œ ë¶€ë¶„ì„ ìš”ì•½í•´ì¤˜"
print(qa.run(query))


âš¡ ì‹¤í–‰:

python test_qa.py

âœ… 2.7. LangSmith / LangFuse ì—°ë™ (ì„ íƒ)

LangSmith: LLM ì‘ë‹µ ì¶”ì ìš©

pip install langsmith
export LANGCHAIN_TRACING_V2=true
export LANGCHAIN_API_KEY=<your_langsmith_key>


LangFuse: í’ˆì§ˆ/ë¡œê·¸ ëª¨ë‹ˆí„°ë§ìš©

pip install langfuse


ê°œë°œ ë‹¨ê³„ì—ì„œëŠ” ê¼­ í•„ìˆ˜ëŠ” ì•„ë‹ˆì§€ë§Œ, ì±—ë´‡ í’ˆì§ˆì„ ë¶„ì„í•˜ê³  ì‹¶ìœ¼ë©´ ì„¤ì •í•´ë‘ë©´ ì¢‹ìŠµë‹ˆë‹¤.

âœ… 2ì¼ì°¨ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

 Azure Cognitive Search ì¸ë±ìŠ¤ ìƒì„± ì„±ê³µ

 Functionì´ Blob ì—…ë¡œë“œ â†’ ì •ê·œì‹ íƒì§€ â†’ ë²¡í„° ì—…ë¡œë“œ ìë™í™”

 test_qa.py ë¡œ LangChain QA ì²´ì¸ ì§ˆì˜ì‘ë‹µ í™•ì¸

 (ì˜µì…˜) LangSmith/LangFuse ì¶”ì  í™œì„±í™”

ğŸ”¥ 3ì¼ì°¨ ë¯¸ë¦¬ë³´ê¸°

Streamlit ì±—ë´‡ UI êµ¬ì¶• (ì‚¬ìš©ì ì…ë ¥ â†’ LangChain QA â†’ ê²°ê³¼ ì¶œë ¥)

ë‚ ì§œ í•„í„° / ë¡œê·¸ íŒŒì¼ëª… í•„í„° ê¸°ëŠ¥ ì¶”ê°€

ìš´ì˜ í™˜ê²½ì—ì„œ Function App ë°°í¬ ë° ì—”ë“œíˆ¬ì—”ë“œ í…ŒìŠ¤íŠ¸

ì´ì œ 2ì¼ì°¨ ë‹¨ê³„ ì¤‘ì—ì„œ

ë¡œê·¸ í¬ë§· ì„¸ë¶€ ì²˜ë¦¬ ë°©ë²•

ì •ê·œì‹ ê´€ë¦¬ (JSON íŒŒì¼ë¡œ ë¶„ë¦¬)

Azure OpenAI vs OpenAI API ì°¨ì´ ì„¤ì •
ê°™ì€ ë¶€ë¶„ì´ ê¶ê¸ˆí•˜ë‹¤ë©´ ì¶”ê°€ë¡œ ì•Œë ¤ë“œë¦´ê¹Œìš”?
ë˜ëŠ” ë°”ë¡œ 2ì¼ì°¨ ì‘ì—…ë¶€í„° ì‹¤í–‰í•´ ë³´ì‹œê² ì–´ìš”?



3ì¼ì°¨ ======================================================================

ì¢‹ì•„ìš”! ì´ì œ 3ì¼ì°¨ì—ì„œ í•  ì¼ë“¤ì„ â€œì™„ì„± Â· ê´€ì¸¡ Â· ë°°í¬ ì§ì „ ê²€ì¦â€ê¹Œì§€ í•œ ë²ˆì— ì •ë¦¬í•´ ë“œë¦´ê²Œìš”.
ìš”ì²­í•˜ì‹  ëŒ€ë¡œ Application Insights(ì•±ì¸ì‚¬ì´íŠ¸) ë¡œê·¸ì™€ LangSmith/LangFuse ì´ë²¤íŠ¸ë„ ë„£ì—ˆìŠµë‹ˆë‹¤.
(ì•„ë˜ ì½”ë“œëŠ” ë°”ë¡œ ë¶™ì—¬ ë„£ì–´ ë™ì‘í•˜ë„ë¡ ìµœì†Œ ì˜ˆì œë¡œ ì •ë¦¬í–ˆì–´ìš”.)

3ì¼ì°¨ ëª©í‘œ

Streamlit UIì—ì„œ ë²¡í„° ê²€ìƒ‰ + QA ë™ì‘

**Function(App)**ê³¼ Streamlit ì–‘ìª½ì— ê´€ì¸¡(Observability) ì¶”ê°€

Application Insights(ì˜¤í”ˆí…”ë ˆë©”íŠ¸ë¦¬ ê¸°ë°˜ ìŠ¤íŒ¬/ë¡œê·¸)

LangSmith/LangFuse ì¶”ì /ì´ë²¤íŠ¸

ì—”ë“œíˆ¬ì—”ë“œ í…ŒìŠ¤íŠ¸ & ìš´ì˜ íŒ

3.1 Function(App) â€” í…”ë ˆë©”íŠ¸ë¦¬ + ì¼ê´€ í•„ë“œ + ì˜ˆì™¸ ë¡œê·¸
(1) ì˜ì¡´ì„±

backend/azure_function/log_uploader/requirements.txtì— ì¶”ê°€:

azure-monitor-opentelemetry
langfuse
langsmith

(2) í™˜ê²½ë³€ìˆ˜ (ë¡œì»¬/ìš´ì˜ ê³µí†µ í‚¤)

APPLICATIONINSIGHTS_CONNECTION_STRING

LANGCHAIN_TRACING_V2=true, LANGSMITH_API_KEY=<your_langsmith_key>

LANGFUSE_HOST, LANGFUSE_PUBLIC_KEY, LANGFUSE_SECRET_KEY (ì›í•˜ì‹¤ ë•Œ)

(ì´ë¯¸ ìˆìœ¼ì‹ ) AZURE_SEARCH_*, AZURE_OPENAI_*

local.settings.json ì˜ˆì‹œëŠ” ì´ì „ì— ë“œë¦° ê²ƒ + ì•„ë˜ í‚¤ë“¤ ì¶”ê°€ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.

(3) function_app.py ë³€ê²½ í¬ì¸íŠ¸ë§Œ ì¶”ê°€

v2 í”„ë¡œê·¸ë˜ë° ëª¨ë¸(ë°ì½”ë ˆì´í„°) ê¸°ì¤€

import logging, os, re, json, uuid, datetime
import azure.functions as func

# --- Application Insights(OpenTelemetry) êµ¬ì„± ---
from azure.monitor.opentelemetry import configure_azure_monitor
if os.getenv("APPLICATIONINSIGHTS_CONNECTION_STRING"):
    configure_azure_monitor(connection_string=os.getenv("APPLICATIONINSIGHTS_CONNECTION_STRING"))

from opentelemetry import trace
tracer = trace.get_tracer("log_ingestor")

# --- LangFuse / LangSmith (ì„ íƒ) ---
from contextlib import suppress
lf, ls_client = None, None
with suppress(Exception):
    from langfuse import Langfuse
    if os.getenv("LANGFUSE_PUBLIC_KEY"):
        lf = Langfuse()  # í™˜ê²½ë³€ìˆ˜ë¡œ ìë™ êµ¬ì„±

with suppress(Exception):
    from langsmith import Client as LSClient
    if os.getenv("LANGSMITH_API_KEY"):
        ls_client = LSClient()

# --- Azure Search / Embeddings: (ì´ë¯¸ êµ¬ì„±í•´ë‘ì‹  ê²ƒê³¼ ë™ì¼) ---
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from langchain_openai import AzureOpenAIEmbeddings

search_client = SearchClient(
    endpoint=os.environ["AZURE_SEARCH_ENDPOINT"],
    index_name=os.environ["SEARCH_INDEX_NAME"],
    credential=AzureKeyCredential(os.environ["AZURE_SEARCH_KEY"])
)
embeddings = AzureOpenAIEmbeddings(
    azure_deployment=os.environ["AZURE_OPENAI_EMBEDDING_DEPLOYMENT"],
    azure_endpoint=os.environ["AZURE_OPENAI_ENDPOINT"],
    api_key=os.environ["AZURE_OPENAI_API_KEY"],
    api_version=os.environ["AZURE_OPENAI_API_VERSION"],
)

app = func.FunctionApp()

@app.function_name(name="LogTrigger")
@app.blob_trigger(arg_name="myblob", path="log-upload/{name}", connection="AzureWebJobsStorage")
def log_trigger(myblob: func.InputStream):
    # ìŠ¤íŒ¬ ì‹œì‘: ì´ ë¸”ë¡­ ì²˜ë¦¬ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ íŠ¸ëœì­ì…˜ìœ¼ë¡œ ì¶”ì 
    with tracer.start_as_current_span("ingest_blob") as span:
        span.set_attribute("blob.name", myblob.name)
        span.set_attribute("blob.size_bytes", myblob.length or 0)

        content = myblob.read().decode("utf-8")
        # ì •ê·œì‹ ë§¤ì¹­ (ì˜ˆì‹œ)
        patterns = [r"Exception", r"Timeout", r"ERROR"]
        matches = [m for p in patterns for m in re.findall(p, content)]

        # íŒŒì¼ëª… í†µì¼(ë² ì´ìŠ¤ëª…ë§Œ ì €ì¥ ê¶Œì¥)
        base_name = os.path.basename(myblob.name)

        # LangFuse trace (ì„ íƒ)
        lf_trace = None
        if lf:
            with suppress(Exception):
                lf_trace = lf.trace(name="ingest_log", input={"filename": base_name})
                lf_trace.event(name="regex_matches",
                               metadata={"match_count": len(matches), "patterns": patterns})

        # LangSmith run (ì„ íƒ)
        ls_run = None
        if ls_client:
            with suppress(Exception):
                ls_run = ls_client.create_run(
                    name="ingest_log",
                    run_type="chain",
                    inputs={"filename": base_name, "size": myblob.length},
                    tags=["ingestion"]
                )

        # ì„ë² ë”© â†’ ìƒ‰ì¸
        vector = embeddings.embed_documents([content])[0]
        doc = {
            "id": str(uuid.uuid4()),
            "content": content,
            "filename": base_name,
            "timestamp": datetime.datetime.utcnow().isoformat(),
            "content_vector": vector
        }

        search_client.merge_or_upload_documents([doc])  # ì¤‘ë³µ ë°©ì§€
        logging.info(f"[Indexed] filename={base_name}, matches={len(matches)}")

        # AppInsights ìŠ¤íŒ¬ ì´ë²¤íŠ¸
        span.add_event("IndexedToSearch", {
            "filename": base_name,
            "match_count": len(matches)
        })

        # LangFuse/LangSmith ë§ˆë¬´ë¦¬
        if lf_trace:
            with suppress(Exception):
                lf_trace.update(output={"doc_id": doc["id"], "match_count": len(matches)})
                lf.flush()

        if ls_run:
            with suppress(Exception):
                ls_client.update_run(
                    run_id=ls_run.id,
                    outputs={"doc_id": doc["id"], "match_count": len(matches)},
                    end_time=datetime.datetime.utcnow()
                )


ì´ë ‡ê²Œ í•˜ë©´ Blob ì—…ë¡œë“œ â†’ Function íŠ¸ë¦¬ê±° â†’ ìƒ‰ì¸ ê³¼ì •ì´ App Insights + LangFuse + LangSmith ëª¨ë‘ì— ë‚¨ìŠµë‹ˆë‹¤.

3.2 Streamlit â€” QA UI + í…”ë ˆë©”íŠ¸ë¦¬
(1) ì˜ì¡´ì„±

frontend/streamlit_app/requirements.txt:

streamlit
langchain
langchain-openai
langchain-community
azure-search-documents
python-dotenv
azure-monitor-opentelemetry
langfuse
langsmith

(2) í™˜ê²½ë³€ìˆ˜

.env(ë¡œì»¬) ë˜ëŠ” ë°°í¬ ì‹œ í™˜ê²½ì„¤ì •ì— ì•„ë˜ í‚¤ ì‚¬ìš©:

Azure OpenAI: AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_API_KEY, AZURE_OPENAI_API_VERSION, AZURE_OPENAI_CHAT_DEPLOYMENT, AZURE_OPENAI_EMBEDDING_DEPLOYMENT

Azure Search: AZURE_SEARCH_ENDPOINT, AZURE_SEARCH_KEY, SEARCH_INDEX_NAME

App Insights: APPLICATIONINSIGHTS_CONNECTION_STRING

LangSmith: LANGCHAIN_TRACING_V2=true, LANGSMITH_API_KEY

LangFuse: LANGFUSE_HOST, LANGFUSE_PUBLIC_KEY, LANGFUSE_SECRET_KEY

(3) app.py
import os, time
import streamlit as st
from dotenv import load_dotenv
load_dotenv()

# --- App Insights(OpenTelemetry) ---
from azure.monitor.opentelemetry import configure_azure_monitor
if os.getenv("APPLICATIONINSIGHTS_CONNECTION_STRING"):
    configure_azure_monitor(connection_string=os.getenv("APPLICATIONINSIGHTS_CONNECTION_STRING"))
from opentelemetry import trace
tracer = trace.get_tracer("streamlit_qa")

# --- LangFuse / LangSmith (optional) ---
from contextlib import suppress
lf, ls_client = None, None
with suppress(Exception):
    from langfuse import Langfuse
    if os.getenv("LANGFUSE_PUBLIC_KEY"):
        lf = Langfuse()
with suppress(Exception):
    from langsmith import Client as LSClient
    if os.getenv("LANGSMITH_API_KEY"):
        ls_client = LSClient()

# --- LLM / Retriever ---
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langchain_community.vectorstores.azuresearch import AzureSearch
from langchain.chains import RetrievalQA

llm = AzureChatOpenAI(
    azure_deployment=os.environ["AZURE_OPENAI_CHAT_DEPLOYMENT"],
    azure_endpoint=os.environ["AZURE_OPENAI_ENDPOINT"],
    api_key=os.environ["AZURE_OPENAI_API_KEY"],
    api_version=os.environ["AZURE_OPENAI_API_VERSION"],
    temperature=0,
)

emb = AzureOpenAIEmbeddings(
    azure_deployment=os.environ["AZURE_OPENAI_EMBEDDING_DEPLOYMENT"],
    azure_endpoint=os.environ["AZURE_OPENAI_ENDPOINT"],
    api_key=os.environ["AZURE_OPENAI_API_KEY"],
    api_version=os.environ["AZURE_OPENAI_API_VERSION"],
)

endpoint = os.environ["AZURE_SEARCH_ENDPOINT"]
key = os.environ["AZURE_SEARCH_KEY"]
index_name = os.getenv("SEARCH_INDEX_NAME", "log-index")

# Vector-only ê¸°ë³¸ (ë²„ì „ ì°¨ì´ í¡ìˆ˜)
try:
    vectorstore = AzureSearch(
        azure_search_endpoint=endpoint,
        azure_search_key=key,
        index_name=index_name,
        embedding=emb,
        vector_field="content_vector",
        text_field="content",
    )
except TypeError:
    vectorstore = AzureSearch(
        azure_search_endpoint=endpoint,
        azure_search_key=key,
        index_name=index_name,
        embedding_function=emb.embed_query,
        vector_field="content_vector",
        text_field="content",
    )

retriever = vectorstore.as_retriever(k=4)

st.set_page_config(page_title="ë¡œê·¸ ë¶„ì„ ì±—ë´‡", page_icon="ğŸªµ")
st.title("ğŸªµ ë¡œê·¸ ë¶„ì„ ì±—ë´‡")

with st.sidebar:
    st.subheader("ê²€ìƒ‰ ì˜µì…˜")
    file_filter = st.text_input("íŒŒì¼ëª… í•„í„° (ì˜ˆ: 2025-09-23.log)", "")
    mode = st.selectbox("ê²€ìƒ‰ ëª¨ë“œ", ["Vector", "Hybrid(ê°€ëŠ¥ ì‹œ)"], index=0)
    k = st.slider("Top-K", min_value=1, max_value=10, value=4)
    st.markdown("---")
    st.caption("LangSmith/LangFuse, AppInsightsë¡œ ìš”ì²­/ì‘ë‹µì´ ì¶”ì ë©ë‹ˆë‹¤.")

query = st.text_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”?", placeholder="ì˜ˆ: 9/23 ë¡œê·¸ì—ì„œ Exception/Timeout ìš”ì•½í•´ì¤˜")

def apply_filter(r, fname: str):
    if not fname:
        return r
    # langchain-community azuresearch ë²„ì „ë§ˆë‹¤ ë‹¤ë¥´ë¯€ë¡œ
    # í•„í„°ë¥¼ retriever ëŒ€ì‹ , ì§ì ‘ similarity_search/hybrid_search í˜¸ì¶œì—ì„œ ì²˜ë¦¬í•˜ëŠ” ê²Œ ì•ˆì „
    return None

if st.button("ì§ˆì˜í•˜ê¸°", type="primary", disabled=not query):
    t0 = time.time()
    # Telemetry span ì‹œì‘
    with tracer.start_as_current_span("qa_query") as span:
        span.set_attribute("query", query)
        span.set_attribute("mode", mode)
        if file_filter:
            span.set_attribute("filter.filename", file_filter)

        # LangFuse/LangSmith trace
        lf_trace, ls_run = None, None
        if lf:
            with suppress(Exception):
                lf_trace = lf.trace(name="qa", input={"query": query, "mode": mode, "filename": file_filter or None})
        if ls_client:
            with suppress(Exception):
                ls_run = ls_client.create_run(name="streamlit_qa", run_type="chain",
                                              inputs={"query": query, "mode": mode, "filename": file_filter or None},
                                              tags=["qa"])

        # ê²€ìƒ‰ + QA
        try:
            # ê°„ë‹¨ êµ¬í˜„: Vector ê¸°ë³¸ / Hybrid ì‹œë„ í›„ ì‹¤íŒ¨í•˜ë©´ Vector fallback
            sources = []
            if mode.startswith("Hybrid"):
                with suppress(Exception):
                    # ì¼ë¶€ ë²„ì „ì—ì„œë§Œ ì œê³µ: hybrid_search
                    sources = vectorstore.hybrid_search(query, k=k)
            if not sources:
                if file_filter:
                    # íŒŒì¼ í•„í„°ê°€ ìˆìœ¼ë©´ ì§ì ‘ similarity_searchë¡œ ì²˜ë¦¬
                    sources = vectorstore.similarity_search(query, k=k, filter={"filename": file_filter})
                else:
                    sources = vectorstore.similarity_search(query, k=k)

            # QA ì²´ì¸
            qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True, chain_type="stuff")
            result = qa.invoke({"query": query})
            answer = result["result"]
            used = result.get("source_documents", []) or sources

            # ì¶œë ¥
            st.subheader("ë‹µë³€")
            st.write(answer)
            st.subheader("ì¶œì²˜")
            for i, d in enumerate(used[:k], 1):
                fname = getattr(d, "metadata", {}).get("filename") if hasattr(d, "metadata") else None
                snippet = d.page_content[:200].replace("\n", " ")
                st.write(f"[{i}] **{fname}** â€” {snippet}...")

            # í…”ë ˆë©”íŠ¸ë¦¬ ê¸°ë¡
            span.set_attribute("latency_ms", int((time.time() - t0) * 1000))
            if lf_trace:
                with suppress(Exception):
                    lf_trace.update(output={"answer": answer[:300]})
                    lf_trace.event(name="qa_sources", metadata={"count": len(used), "filenames": [getattr(d, 'metadata', {}).get('filename') for d in used]})
                    lf.flush()
            if ls_run:
                with suppress(Exception):
                    ls_client.update_run(run_id=ls_run.id, outputs={"answer": answer[:300]}, end_time=None)

        except Exception as e:
            st.error(f"ì˜¤ë¥˜: {e}")
            span.record_exception(e)
            if lf_trace:
                with suppress(Exception):
                    lf_trace.event(name="qa_error", level="error", metadata={"error": str(e)})
                    lf.flush()
            if ls_run:
                with suppress(Exception):
                    ls_client.update_run(run_id=ls_run.id, error=str(e))


ê¸°ë³¸ì€ ë²¡í„° ê²€ìƒ‰, ê°€ëŠ¥í•˜ë©´ í•˜ì´ë¸Œë¦¬ë“œë„ ì‹œë„í•©ë‹ˆë‹¤(ë²„ì „ ì°¨ë¡œ ì‹¤íŒ¨í•˜ë©´ ìë™ ë²¡í„° fallback).
filename í•„í„°ëŠ” ì¸ë±ì‹± ì‹œ filenameì„ ë² ì´ìŠ¤ëª…ìœ¼ë¡œ ì €ì¥í•´ ë‘ì…¨ìœ¼ë‹ˆ ê·¸ëŒ€ë¡œ í•„í„°ë¡œ ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

3.3 ê´€ì¸¡(Observability) â€” í™•ì¸í•˜ëŠ” ë²•
Application Insights (KQL ì˜ˆì‹œ)

Function ì¸ë±ì‹± ì™„ë£Œ ì´ë²¤íŠ¸(ìš°ë¦¬ ìŠ¤íŒ¬/ë¡œê·¸):

traces
| where message has "Indexed" or customDimensions["filename"] != ""
| order by timestamp desc


ìŠ¤íŒ¬ ì´ë¦„ìœ¼ë¡œ ë³´ê¸°:

traces
| where operation_Name == "ingest_blob" or operation_Name == "qa_query"
| order by timestamp desc


ì˜ˆì™¸/ì˜¤ë¥˜ë§Œ:

exceptions
| order by timestamp desc

LangSmith

LANGCHAIN_TRACING_V2=true + LANGSMITH_API_KEY ì„¤ì • í›„
LangSmith ì›¹ ì½˜ì†”ì—ì„œ í”„ë¡œì íŠ¸/ëŸ°ìœ¼ë¡œ í™•ì¸(ì²´ì¸ ì´ë¦„: ingest_log, streamlit_qa).

LangFuse

LANGFUSE_* í‚¤ ì„¤ì • í›„
LangFuse ëŒ€ì‹œë³´ë“œì—ì„œ Trace ingest_log/qa, Event regex_matches/qa_sources/qa_error í™•ì¸.

3.4 ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

 Function(App)ì—ì„œ íŒŒì¼ ì—…ë¡œë“œ ì‹œ ë¡œê·¸/ìŠ¤íŒ¬/ì´ë²¤íŠ¸ê°€ ê° ëŒ€ì‹œë³´ë“œì— ì°íˆëŠ”ì§€

 Streamlitì—ì„œ ì§ˆì˜ ìš”ì²­ ì‹œ ìŠ¤íŒ¬/ì´ë²¤íŠ¸ê°€ ì°íˆëŠ”ì§€

 filename í•„í„°ë¡œ ì›í•˜ëŠ” íŒŒì¼ë§Œ ê²€ìƒ‰ë˜ëŠ”ì§€

 (ì›í•œë‹¤ë©´) ì²­í¬ ë¶„í• ë¡œ ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ (ë¡œê·¸ ë¼ì¸ ê¸°ì¤€ split â†’ ê¸¸ì´ 800~1200ìë¡œ ì—…ë¡œë“œ)

 Function App ë°°í¬:
func azure functionapp publish <FUNCTION_APP_NAME>
App Settingsì— ìœ„ í™˜ê²½ë³€ìˆ˜ ëª¨ë‘ ë“±ë¡

3.5 ì‘ì€ ê°œì„  ì•„ì´ë””ì–´ (ì„ íƒ)

ì¤‘ë³µ ë°©ì§€ë¥¼ ë” ê°•í•˜ê²Œ: id = f"{base_name}:{sha1(chunk)}" í˜•íƒœ ê³ ì • + merge_or_upload

í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê³µì‹í™”: Azure SDKì˜ SearchClient.search(search_text + vector_queries)ë¡œ êµ¬í˜„

ì²˜ë¦¬ ìƒíƒœ í‘œì‹œ: Functionì—ì„œ indexed:<filename> ë¡œê·¸ë¥¼ ë‚¨ê¸°ê³ , Streamlit ì¸¡ì—ì„œ Searchë¡œ í´ë§í•´ â€œì²˜ë¦¬ ì™„ë£Œâ€ ë°°ì§€ í‘œì‹œ

í•„ìš”í•˜ì‹œë©´ ì²­í¬ ë¶„í•  ì—…ë¡œë“œ ì½”ë“œì™€ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰(REST/SDK) ì •ì‹ êµ¬í˜„ë„ ë°”ë¡œ ë¶™ì—¬ë“œë¦´ê²Œìš”.
ì—¬ê¸°ê¹Œì§€ ì ìš©í•˜ë©´ 3ì¼ì°¨ ëª©í‘œ(í”„ë¡ íŠ¸ + ê´€ì¸¡ + E2E) ì™„ë£Œì…ë‹ˆë‹¤.